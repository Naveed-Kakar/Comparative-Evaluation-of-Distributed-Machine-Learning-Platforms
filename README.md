# Comparative-Evaluation-of-Distributed-Machine-Learning-Platforms
The simultaneous growth in availability of big data and in the number of simultaneous users on the
Internet places particular pressure on the need to carry out computing tasks “in parallel,” or
simultaneously. Parallel and distributed computing occurs across many different topic areas in
computer science, including algorithms, computer architecture, networks, operating systems, Machine
Learning, and software engineering. During the early 21st century there was explosive growth in
multiprocessor design and other strategies for complex applications to run faster. Parallel and
distributed computing builds on fundamental systems concepts, such as concurrency, Programming
Models, consistency in state/memory manipulation, message-passing, and shared-memory models.
